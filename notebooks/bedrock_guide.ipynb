{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679ab403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeac55b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../guide_scripts/list_foundation_models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../guide_scripts/list_foundation_models.py\n",
    "import logging\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# Lists the available Amazon Bedrock models.\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "def list_foundation_models(bedrock_client):\n",
    "    \"\"\"\n",
    "    Gets a list of available Amazon Bedrock foundation models.\n",
    "    :return: The list of available bedrock foundation models.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = bedrock_client.list_foundation_models()\n",
    "        models = response[\"modelSummaries\"]\n",
    "        logger.info(\"Got %s foundation models.\", len(models))\n",
    "        return models\n",
    "    except ClientError:\n",
    "        logger.error(\"Couldn't list foundation models.\")\n",
    "        raise Exception(\"Couldn't list foundation models.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Entry point for the example. Uses the AWS SDK for Python (Boto3)\n",
    "    to create an Amazon Bedrock client. Then lists the available Bedrock models\n",
    "    in the region set in the callers profile and credentials.\n",
    "    \"\"\"\n",
    "    bedrock_client = boto3.client(service_name=\"bedrock\")\n",
    "    fm_models = list_foundation_models(bedrock_client)\n",
    "    for model in fm_models:\n",
    "        print(f\"Model: {model['modelName']}\")\n",
    "        print(json.dumps(model, indent=2))\n",
    "        print(\"---------------------------\\n\")\n",
    "    logger.info(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f616409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../guide_scripts/invoke_titan_text_express.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../guide_scripts/invoke_titan_text_express.py\n",
    "# Use the native inference API to send a text message to Amazon Titan Text G1 -\n",
    "# Express.\n",
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create an Amazon Bedrock Runtime client.\n",
    "brt = boto3.client(\"bedrock-runtime\")\n",
    "# Set the model ID, e.g., Amazon Titan Text G1 - Express.\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "# Define the prompt for the model.\n",
    "prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "# Format the request payload using the model's native structure.\n",
    "native_request = {\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "    \"maxTokenCount\": 512,\n",
    "    \"temperature\": 0.7,\n",
    "    \"topP\": 0.9\n",
    "    },\n",
    "}\n",
    "# Convert the native request to JSON.\n",
    "request = json.dumps(native_request)\n",
    "try:\n",
    "    # Invoke the model with the request.\n",
    "    response = brt.invoke_model(modelId=model_id, body=request)\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Decode the response body.\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "# Extract and print the response text.\n",
    "response_text = model_response[\"results\"][0][\"outputText\"]\n",
    "\n",
    "print(f\"Response: {response_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96011b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../guide_scripts/generate_text_response_converse.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../guide_scripts/generate_text_response_converse.py\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create an Amazon Bedrock Runtime client.\n",
    "brt = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "# Set the model ID, e.g., Amazon Titan Text G1 - Express.\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "inference_config = {\n",
    "     'maxTokens': 512,\n",
    "     'temperature': 0.5,\n",
    "     'topP': 0.9\n",
    "}\n",
    "performanceConfig={\n",
    "    'latency': 'standard'\n",
    "}\n",
    "# Start a conversation with the user message.\n",
    "user_message = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"text\": \"A 'hello world' program demonstrates the basic syntax of a programming language.\"}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"What is the purpose of a 'hello world' program in Python?\"}],\n",
    "    },\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = brt.converse(\n",
    "        modelId=model_id,\n",
    "        messages=conversation,\n",
    "        inferenceConfig=inference_config,\n",
    "        performanceConfig=performanceConfig,\n",
    "    )\n",
    "    response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "except ClientError as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa887b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_region = \"us-east-1\"\n",
    "bedrock_client = boto3.client(service_name=\"bedrock\", region_name=aws_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965d85ca",
   "metadata": {},
   "source": [
    "### Using DSPY and Bedrock CoT (Proof of Concept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e95f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from aws_keys import AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION\n",
    "\n",
    "# Set the AWS credentials as environment variables\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
    "os.environ[\"AWS_REGION\"] = AWS_REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bd55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "lm = dspy.LM('bedrock/amazon.nova-pro-v1:0')\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220bb23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = dspy.Predict(\"question:str -> answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3adef800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot = dspy.ChainOfThought(\"question -> answer\")\n",
    "question = \"True of False: The numbers in this group add up to an even number: 17,  8, 10, 12, 13, 4, 2.\"\n",
    "cot(question=question).answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436d6db",
   "metadata": {},
   "source": [
    "### Continuing Bedrock Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42443291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../guide_scripts/meeting_transcript.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../guide_scripts/meeting_transcript.py\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Shows how to create a list of action items from a meeting transcript\n",
    "with the Amazon Titan Text model (on demand).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ImageError(Exception):\n",
    "    \"Custom exception for errors returned by Amazon Titan Text models\"\n",
    "\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def generate_text(model_id, body):\n",
    "    \"\"\"\n",
    "    Generate text using Amazon Titan Text models on demand.\n",
    "    Args:\n",
    "        model_id (str): The model ID to use.\n",
    "        body (str) : The request body to use.\n",
    "    Returns:\n",
    "        response (json): The response from the model.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\n",
    "        \"Generating text with Amazon Titan Text model %s\", model_id)\n",
    "\n",
    "    bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=model_id, accept=accept, contentType=content_type\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    finish_reason = response_body.get(\"error\")\n",
    "\n",
    "    if finish_reason is not None:\n",
    "        raise ImageError(f\"Text generation error. Error is {finish_reason}\")\n",
    "\n",
    "    logger.info(\n",
    "        \"Successfully generated text with Amazon Titan Text model %s\", model_id)\n",
    "\n",
    "    return response_body\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Entrypoint for Amazon Titan Text model example.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.basicConfig(level=logging.INFO,\n",
    "                            format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "        # You can replace the model_id with any other Titan Text Models\n",
    "        # Titan Text Model family model_id is as mentioned below:\n",
    "        # amazon.titan-text-premier-v1:0, amazon.titan-text-express-v1, amazon.titan-text-lite-v1\n",
    "        model_id = 'amazon.titan-text-express-v1'\n",
    "\n",
    "        prompt = \"\"\"Meeting transcript: Miguel: Hi Brant, I want to discuss the workstream  \n",
    "            for our new product launch Brant: Sure Miguel, is there anything in particular you want\n",
    "            to discuss? Miguel: Yes, I want to talk about how users enter into the product.\n",
    "            Brant: Ok, in that case let me add in Namita. Namita: Hey everyone \n",
    "            Brant: Hi Namita, Miguel wants to discuss how users enter into the product.\n",
    "            Miguel: its too complicated and we should remove friction.  \n",
    "            for example, why do I need to fill out additional forms?  \n",
    "            I also find it difficult to find where to access the product\n",
    "            when I first land on the landing page. Brant: I would also add that\n",
    "            I think there are too many steps. Namita: Ok, I can work on the\n",
    "            landing page to make the product more discoverable but brant\n",
    "            can you work on the additonal forms? Brant: Yes but I would need \n",
    "            to work with James from another team as he needs to unblock the sign up workflow.\n",
    "            Miguel can you document any other concerns so that I can discuss with James only once?\n",
    "            Miguel: Sure.\n",
    "            From the meeting transcript above, Create a list of action items for each person. \"\"\"\n",
    "\n",
    "        body = json.dumps({\n",
    "            \"inputText\": prompt,\n",
    "            \"textGenerationConfig\": {\n",
    "                \"maxTokenCount\": 4096,\n",
    "                \"stopSequences\": [],\n",
    "                \"temperature\": 0.7,\n",
    "                \"topP\": 0.9\n",
    "            }\n",
    "        })\n",
    "\n",
    "        response_body = generate_text(model_id, body)\n",
    "        print(f\"Input token count: {response_body['inputTextTokenCount']}\")\n",
    "\n",
    "        for result in response_body['results']:\n",
    "            print(f\"Token count: {result['tokenCount']}\")\n",
    "            print(f\"Output text: {result['outputText']}\")\n",
    "            print(f\"Completion reason: {result['completionReason']}\")\n",
    "\n",
    "    except ClientError as err:\n",
    "        message = err.response[\"Error\"][\"Message\"]\n",
    "        logger.error(\"A client error occurred: %s\", message)\n",
    "        print(\"A client error occured: \" +\n",
    "              format(message))\n",
    "    except ImageError as err:\n",
    "        logger.error(err.message)\n",
    "        print(err.message)\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            f\"Finished generating text with the Amazon Titan Text Premier model {model_id}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd2860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating text with model amazon.nova-pro-v1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the most popular song on WZPZ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Requesting tool top_song. Request: tooluse_eVs-vdanS365uOINnTtaHQ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"text\": \"The most popular song on WZPZ is \\\"Elemental Hotel\\\" by 8 Storey Hike.\"\n",
      "}\n",
      "Finished generating text with model amazon.nova-pro-v1:0.\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ../guide_scripts/tool_call.py\n",
    "import logging\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\"\"\"\n",
    "Shows how to use tools with the <noloc>Converse</noloc> API and the Cohere Command R model.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class StationNotFoundError(Exception):\n",
    "    \"\"\"Raised when a radio station isn't found.\"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def get_top_song(call_sign):\n",
    "    \"\"\"Returns the most popular song for the requested station.\n",
    "    Args:\n",
    "        call_sign (str): The call sign for the station for which you want\n",
    "        the most popular song.\n",
    "\n",
    "    Returns:\n",
    "        response (json): The most popular song and artist.\n",
    "    \"\"\"\n",
    "\n",
    "    song = \"\"\n",
    "    artist = \"\"\n",
    "    if call_sign == \"WZPZ\":\n",
    "        song = \"Elemental Hotel\"\n",
    "        artist = \"8 Storey Hike\"\n",
    "\n",
    "    else:\n",
    "        raise StationNotFoundError(f\"Station {call_sign} not found.\")\n",
    "\n",
    "    return song, artist\n",
    "\n",
    "\n",
    "def generate_text(bedrock_client, model_id, tool_config, input_text):\n",
    "    \"\"\"Generates text using the supplied Amazon Bedrock model. If necessary,\n",
    "    the function handles tool use requests and sends the result to the model.\n",
    "    Args:\n",
    "        bedrock_client: The Boto3 Bedrock runtime client.\n",
    "        model_id (str): The Amazon Bedrock model ID.\n",
    "        tool_config (dict): The tool configuration.\n",
    "        input_text (str): The input text.\n",
    "    Returns:\n",
    "        Nothing.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"Generating text with model %s\", model_id)\n",
    "\n",
    "    # Create the initial message from the user input.\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": input_text}]}]\n",
    "\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model_id, messages=messages, toolConfig=tool_config\n",
    "    )\n",
    "\n",
    "    output_message = response[\"output\"][\"message\"]\n",
    "    messages.append(output_message)\n",
    "    stop_reason = response[\"stopReason\"]\n",
    "\n",
    "    if stop_reason == \"tool_use\":\n",
    "        # Tool use requested. Call the tool and send the result to the model.\n",
    "        tool_requests = response[\"output\"][\"message\"][\"content\"]\n",
    "        for tool_request in tool_requests:\n",
    "            if \"toolUse\" in tool_request:\n",
    "                tool = tool_request[\"toolUse\"]\n",
    "                logger.info(\n",
    "                    \"Requesting tool %s. Request: %s\", tool[\"name\"], tool[\"toolUseId\"]\n",
    "                )\n",
    "\n",
    "                if tool[\"name\"] == \"top_song\":\n",
    "                    tool_result = {}\n",
    "                    try:\n",
    "                        song, artist = get_top_song(tool[\"input\"][\"sign\"])\n",
    "                        tool_result = {\n",
    "                            \"toolUseId\": tool[\"toolUseId\"],\n",
    "                            \"content\": [{\"json\": {\"song\": song, \"artist\": artist}}],\n",
    "                        }\n",
    "                    except StationNotFoundError as err:\n",
    "                        tool_result = {\n",
    "                            \"toolUseId\": tool[\"toolUseId\"],\n",
    "                            \"content\": [{\"text\": err.args[0]}],\n",
    "                            \"status\": \"error\",\n",
    "                        }\n",
    "\n",
    "                    tool_result_message = {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [{\"toolResult\": tool_result}],\n",
    "                    }\n",
    "                    messages.append(tool_result_message)\n",
    "\n",
    "                    # Send the tool result to the model.\n",
    "                    response = bedrock_client.converse(\n",
    "                        modelId=model_id, messages=messages, toolConfig=tool_config\n",
    "                    )\n",
    "                    output_message = response[\"output\"][\"message\"]\n",
    "\n",
    "    # print the final response from the model.\n",
    "    for content in output_message[\"content\"]:\n",
    "        print(json.dumps(content, indent=4))\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Entrypoint for tool use example.\n",
    "    \"\"\"\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "    model_id = \"amazon.nova-pro-v1:0\"\n",
    "    input_text = \"What is the most popular song on WZPZ?\"\n",
    "\n",
    "    tool_config = {\n",
    "        \"tools\": [\n",
    "            {\n",
    "                \"toolSpec\": {\n",
    "                    \"name\": \"top_song\",\n",
    "                    \"description\": \"Get the most popular song played on a radio station.\",\n",
    "                    \"inputSchema\": {\n",
    "                        \"json\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"sign\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The call sign for the radio station for which you want the most popular song. Example calls signs are WZPZ, and WKRP.\",\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"sign\"],\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    bedrock_client = boto3.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "    try:\n",
    "        print(f\"Question: {input_text}\")\n",
    "        generate_text(bedrock_client, model_id, tool_config, input_text)\n",
    "\n",
    "    except ClientError as err:\n",
    "        message = err.response[\"Error\"][\"Message\"]\n",
    "        logger.error(\"A client error occurred: %s\", message)\n",
    "        print(f\"A client error occured: {message}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Finished generating text with model {model_id}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646853e",
   "metadata": {},
   "source": [
    "## Bedrock Agent Prompt Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c62eb89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt in Prompt management\n",
    "import boto3\n",
    "\n",
    "# Create an Amazon Bedrock Agents client\n",
    "client = boto3.client(service_name=\"bedrock-agent\")\n",
    "\n",
    "# Create the prompt\n",
    "response = client.create_prompt(\n",
    "    name=\"MakePlaylist1\",\n",
    "    description=\"My first prompt.\",\n",
    "    variants=[\n",
    "        { \n",
    "            \"name\": \"Variant1\",\n",
    "            \"modelId\": \"amazon.titan-text-express-v1\",\n",
    "            \"templateType\": \"TEXT\",\n",
    "            \"inferenceConfiguration\": {\n",
    "                \"text\": {\n",
    "                    \"temperature\": 0.8\n",
    "                }\n",
    "            },\n",
    "            \"templateConfiguration\": { \n",
    "                \"text\": {\n",
    "                    \"text\": \"Make me a {{genre}} playlist consisting of the following number of songs: {{number}}.\"\n",
    "                }\n",
    "            }\n",
    "      }\n",
    "    ]\n",
    ")\n",
    "                        \n",
    "prompt_id = response.get(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aab24dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt version ARN: arn:aws:bedrock:us-east-1:914839022649:prompt/VI56XO1NBZ:2, Prompt version: 2\n"
     ]
    }
   ],
   "source": [
    "client.list_prompts()\n",
    "client.get_prompt(promptIdentifier=prompt_id)\n",
    "# Create a version of the prompt that you created\n",
    "response = client.create_prompt_version(promptIdentifier=prompt_id)\n",
    "                        \n",
    "prompt_version = response.get(\"version\")\n",
    "prompt_version_arn = response.get(\"arn\")\n",
    "print(f\"Prompt version ARN: {prompt_version_arn}, Prompt version: {prompt_version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3139a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '30e024cb-7111-4071-bc4e-8dbe4b80176a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sat, 19 Apr 2025 15:55:22 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '507',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '30e024cb-7111-4071-bc4e-8dbe4b80176a',\n",
       "   'x-amz-apigw-id': 'JRwYrHicIAMEkeA=',\n",
       "   'x-amzn-trace-id': 'Root=1-6803c76a-03047257691a074f2cab7e98'},\n",
       "  'RetryAttempts': 0},\n",
       " 'arn': 'arn:aws:bedrock:us-east-1:914839022649:prompt/VI56XO1NBZ:2',\n",
       " 'createdAt': datetime.datetime(2025, 4, 19, 15, 53, 30, 159112, tzinfo=tzutc()),\n",
       " 'id': 'VI56XO1NBZ',\n",
       " 'name': 'MakePlaylist1',\n",
       " 'updatedAt': datetime.datetime(2025, 4, 19, 15, 53, 30, 159112, tzinfo=tzutc()),\n",
       " 'variants': [{'inferenceConfiguration': {'text': {'temperature': 0.800000011920929}},\n",
       "   'modelId': 'amazon.titan-text-express-v1',\n",
       "   'name': 'Variant1',\n",
       "   'templateConfiguration': {'text': {'text': 'Make me a {{genre}} playlist consisting of the following number of songs: {{number}}.'}},\n",
       "   'templateType': 'TEXT'}],\n",
       " 'version': '2'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_prompts(promptIdentifier='VI56XO1NBZ')\n",
    "client.get_prompt(promptIdentifier='VI56XO1NBZ', promptVersion=prompt_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c99424b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../guide_scripts/prompt_management_flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../guide_scripts/prompt_management_flow.py\n",
    "# Import Python SDK and create client\n",
    "import boto3\n",
    "\n",
    "client = boto3.client(service_name='bedrock-agent')\n",
    "\n",
    "FLOWS_SERVICE_ROLE = \"arn:aws:iam::123456789012:role/MyPromptFlowsRole\" # Flows service role that you created. For more information, see https://docs.aws.amazon.com/bedrock/latest/userguide/flows-permissions.html\n",
    "PROMPT_ARN = prompt_version_arn # ARN of the prompt that you created, retrieved programatically during creation.\n",
    "\n",
    "# Define each node\n",
    "\n",
    "# The input node validates that the content of the InvokeFlow request is a JSON object.\n",
    "input_node = {\n",
    "    \"type\": \"Input\",\n",
    "    \"name\": \"FlowInput\",\n",
    "    \"outputs\": [\n",
    "        {\n",
    "            \"name\": \"document\",\n",
    "            \"type\": \"Object\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# This prompt node contains a prompt that you defined in Prompt management.\n",
    "# It validates that the input is a JSON object that minimally contains the fields \"genre\" and \"number\", which it will map to the prompt variables.\n",
    "# The output must be named \"modelCompletion\" and be of the type \"String\".\n",
    "prompt_node = {\n",
    "    \"type\": \"Prompt\",\n",
    "    \"name\": \"MakePlaylist\",\n",
    "    \"configuration\": {\n",
    "        \"prompt\": {\n",
    "            \"sourceConfiguration\": {\n",
    "                \"resource\": {\n",
    "                    \"promptArn\": \"\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"genre\",\n",
    "            \"type\": \"String\",\n",
    "            \"expression\": \"$.data.genre\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"number\",\n",
    "            \"type\": \"Number\",\n",
    "            \"expression\": \"$.data.number\"\n",
    "        }\n",
    "    ],\n",
    "    \"outputs\": [\n",
    "        {\n",
    "            \"name\": \"modelCompletion\",\n",
    "            \"type\": \"String\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# The output node validates that the output from the last node is a string and returns it as is. The name must be \"document\".\n",
    "output_node = {\n",
    "    \"type\": \"Output\",\n",
    "    \"name\": \"FlowOutput\",\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"document\",\n",
    "            \"type\": \"String\",\n",
    "            \"expression\": \"$.data\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create connections between the nodes\n",
    "connections = []\n",
    "\n",
    "#   First, create connections between the output of the flow input node and each input of the prompt node\n",
    "for input in prompt_node[\"inputs\"]:\n",
    "    connections.append(\n",
    "        {\n",
    "            \"name\": \"_\".join([input_node[\"name\"], prompt_node[\"name\"], input[\"name\"]]),\n",
    "            \"source\": input_node[\"name\"],\n",
    "            \"target\": prompt_node[\"name\"],\n",
    "            \"type\": \"Data\",\n",
    "            \"configuration\": {\n",
    "                \"data\": {\n",
    "                    \"sourceOutput\": input_node[\"outputs\"][0][\"name\"],\n",
    "                    \"targetInput\": input[\"name\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Then, create a connection between the output of the prompt node and the input of the flow output node\n",
    "connections.append(\n",
    "    {\n",
    "        \"name\": \"_\".join([prompt_node[\"name\"], output_node[\"name\"]]),\n",
    "        \"source\": prompt_node[\"name\"],\n",
    "        \"target\": output_node[\"name\"],\n",
    "        \"type\": \"Data\",\n",
    "        \"configuration\": {\n",
    "            \"data\": {\n",
    "                \"sourceOutput\": prompt_node[\"outputs\"][0][\"name\"],\n",
    "                \"targetInput\": output_node[\"inputs\"][0][\"name\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create the flow from the nodes and connections\n",
    "client.create_flow(\n",
    "    name=\"FlowCreatePlaylist\",\n",
    "    description=\"A flow that creates a playlist given a genre and number of songs to include in the playlist.\",\n",
    "    executionRoleArn=FLOWS_SERVICE_ROLE,\n",
    "    definition={\n",
    "        \"nodes\": [input_node, prompt_node, output_node],\n",
    "        \"connections\": connections\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f0c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
